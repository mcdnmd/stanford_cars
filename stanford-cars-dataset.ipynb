{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-21T05:52:54.482594Z","iopub.status.busy":"2023-11-21T05:52:54.481962Z","iopub.status.idle":"2023-11-21T05:53:19.425905Z","shell.execute_reply":"2023-11-21T05:53:19.424803Z","shell.execute_reply.started":"2023-11-21T05:52:54.482567Z"},"trusted":true},"outputs":[],"source":["!pip -q install mat73 torcheval\n","!pip install -U albumentations"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-21T05:53:19.428410Z","iopub.status.busy":"2023-11-21T05:53:19.428043Z","iopub.status.idle":"2023-11-21T05:53:24.601105Z","shell.execute_reply":"2023-11-21T05:53:24.600287Z","shell.execute_reply.started":"2023-11-21T05:53:19.428375Z"},"trusted":true},"outputs":[],"source":["import os\n","import cv2\n","import json\n","import scipy.io\n","import shutil\n","import yaml\n","import requests\n","import random\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","\n","from path import Path\n","from tqdm import tqdm\n","from PIL import Image\n","\n","import matplotlib.pyplot as plt\n","import albumentations as A\n","from albumentations.pytorch.transforms import ToTensorV2, ToTensor\n","\n","from torch.utils.data import Dataset, DataLoader\n","from torcheval.metrics.functional import multiclass_f1_score, multiclass_accuracy\n","%matplotlib inline"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-11-21T05:53:24.602548Z","iopub.status.busy":"2023-11-21T05:53:24.602168Z","iopub.status.idle":"2023-11-21T05:53:24.614644Z","shell.execute_reply":"2023-11-21T05:53:24.606593Z","shell.execute_reply.started":"2023-11-21T05:53:24.602521Z"},"trusted":true},"outputs":[],"source":["ROOT_DIR = Path('/kaggle/')\n","INPUT_DIR = ROOT_DIR / \"input\"\n","WORKING_DIR = ROOT_DIR / \"working\"\n","DATASET_DIR = INPUT_DIR / \"stanford-cars-dataset\"\n","ANNOTATIONS_DIR = INPUT_DIR / \"stanford-cars-dataset-annotations\"\n","\n","TRAIN_DIR = WORKING_DIR / \"train\"\n","VAL_DIR = WORKING_DIR / \"val\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-21T05:53:24.617519Z","iopub.status.busy":"2023-11-21T05:53:24.617185Z","iopub.status.idle":"2023-11-21T05:53:25.576523Z","shell.execute_reply":"2023-11-21T05:53:25.575428Z","shell.execute_reply.started":"2023-11-21T05:53:24.617486Z"},"trusted":true},"outputs":[],"source":["!ls $DATASET_DIR"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-21T05:56:03.132949Z","iopub.status.busy":"2023-11-21T05:56:03.131503Z","iopub.status.idle":"2023-11-21T05:56:03.147526Z","shell.execute_reply":"2023-11-21T05:56:03.146307Z","shell.execute_reply.started":"2023-11-21T05:56:03.132901Z"},"trusted":true},"outputs":[],"source":["class StanfordCarsDataset(Dataset):\n","    def __init__(self, source_path: str, annotation_path: str, transforms: callable = None):\n","        self.source_paths = self.__load_imgs_paths(source_path)\n","        self.labels = self.__load_labels(annotation_path)\n","        self.transforms = transforms\n","\n","    def __load_imgs_paths(self, path: Path) -> list[Path]:\n","        if not os.path.exists(path):\n","            raise ValueError(\"Not found file %s\" % str(path))\n","        return [path / filename for filename in os.listdir(path) if os.path.isfile(path / filename)]\n","    \n","    def __load_labels(self, path: Path):\n","        if not os.path.exists(path):\n","            raise ValueError(\"Not found file %s\" % str(path))\n","            \n","        lable_mat = scipy.io.loadmat(path)\n","        labels = {}\n","        for arr in lable_mat['annotations'][0]:\n","            filename, label = str(arr[5][0]), int(arr[4][0,0])-1\n","            labels[filename] = label\n","\n","        return labels\n","    \n","    @property\n","    def features_amount(self) -> int:\n","        return len(set(self.labels))\n","\n","    def __len__(self):\n","        return len(self.source_paths)\n","\n","    def __getitem__(self, index):\n","        img_path = self.source_paths[index]\n","        img = Image.open(img_path).convert('RGB')\n","        label = self.labels[os.path.basename(img_path)]\n","    \n","        if self.transforms:\n","            img = self.transforms(image=np.array(img))['image']\n","            img = img.to(torch.float)\n","            \n","        return img, label"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-21T05:56:03.180112Z","iopub.status.busy":"2023-11-21T05:56:03.179483Z","iopub.status.idle":"2023-11-21T05:56:03.185261Z","shell.execute_reply":"2023-11-21T05:56:03.184340Z","shell.execute_reply.started":"2023-11-21T05:56:03.180082Z"},"trusted":true},"outputs":[],"source":["transform = A.Compose([\n","    A.Resize(width=224, height=224),\n","    A.HorizontalFlip(p=0.5),\n","    A.RandomBrightnessContrast(p=0.2),\n","    ToTensorV2(),\n","])\n","\n","test_transform = A.Compose([\n","    A.Resize(width=224, height=224),\n","    ToTensorV2(),\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-21T05:56:03.201786Z","iopub.status.busy":"2023-11-21T05:56:03.201495Z","iopub.status.idle":"2023-11-21T05:56:07.148553Z","shell.execute_reply":"2023-11-21T05:56:07.147776Z","shell.execute_reply.started":"2023-11-21T05:56:03.201752Z"},"trusted":true},"outputs":[],"source":["train_dataset = StanfordCarsDataset(\n","    source_path=DATASET_DIR / \"cars_train/cars_train\",\n","    annotation_path=ANNOTATIONS_DIR / \"cars_train_annos.mat\",\n","    transforms=transform,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-21T05:56:07.150574Z","iopub.status.busy":"2023-11-21T05:56:07.150265Z","iopub.status.idle":"2023-11-21T05:56:11.311497Z","shell.execute_reply":"2023-11-21T05:56:11.310724Z","shell.execute_reply.started":"2023-11-21T05:56:07.150547Z"},"trusted":true},"outputs":[],"source":["test_dataset = StanfordCarsDataset(\n","    source_path=DATASET_DIR / \"cars_test/cars_test\",\n","    annotation_path=ANNOTATIONS_DIR / \"cars_test_annos_withlabels_eval.mat\",\n","    transforms=test_transform,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-21T05:56:11.312922Z","iopub.status.busy":"2023-11-21T05:56:11.312629Z","iopub.status.idle":"2023-11-21T05:56:11.325430Z","shell.execute_reply":"2023-11-21T05:56:11.324709Z","shell.execute_reply.started":"2023-11-21T05:56:11.312897Z"},"trusted":true},"outputs":[],"source":["train_image, lable = train_dataset[0]\n","test_image, lable = test_dataset[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-21T05:56:11.327047Z","iopub.status.busy":"2023-11-21T05:56:11.326640Z","iopub.status.idle":"2023-11-21T05:56:11.359815Z","shell.execute_reply":"2023-11-21T05:56:11.358982Z","shell.execute_reply.started":"2023-11-21T05:56:11.327022Z"},"trusted":true},"outputs":[],"source":["test_image"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-21T05:56:11.362843Z","iopub.status.busy":"2023-11-21T05:56:11.362555Z","iopub.status.idle":"2023-11-21T05:56:11.368898Z","shell.execute_reply":"2023-11-21T05:56:11.368012Z","shell.execute_reply.started":"2023-11-21T05:56:11.362820Z"},"trusted":true},"outputs":[],"source":["def display_image_grid():\n","    rows = 1\n","    cols = 2\n","    figure, ax = plt.subplots(nrows=rows, ncols=cols, figsize=(12, 6))\n","    for i, t in enumerate([train_dataset[random.randint(1, 1000)], test_dataset[random.randint(1, 1000)]]):\n","        img, label = t\n","        ax.ravel()[i].imshow(img.T)\n","        ax.ravel()[i].set_title(label)\n","        ax.ravel()[i].set_axis_off()\n","    plt.tight_layout()\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-21T05:56:11.370427Z","iopub.status.busy":"2023-11-21T05:56:11.370114Z","iopub.status.idle":"2023-11-21T05:56:11.809587Z","shell.execute_reply":"2023-11-21T05:56:11.808762Z","shell.execute_reply.started":"2023-11-21T05:56:11.370402Z"},"trusted":true},"outputs":[],"source":["display_image_grid()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-21T05:56:11.811250Z","iopub.status.busy":"2023-11-21T05:56:11.810904Z","iopub.status.idle":"2023-11-21T05:56:11.816594Z","shell.execute_reply":"2023-11-21T05:56:11.815759Z","shell.execute_reply.started":"2023-11-21T05:56:11.811217Z"},"trusted":true},"outputs":[],"source":["train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n","test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-21T05:56:11.818118Z","iopub.status.busy":"2023-11-21T05:56:11.817835Z","iopub.status.idle":"2023-11-21T05:56:11.827697Z","shell.execute_reply":"2023-11-21T05:56:11.826921Z","shell.execute_reply.started":"2023-11-21T05:56:11.818087Z"},"trusted":true},"outputs":[],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-21T05:56:11.829367Z","iopub.status.busy":"2023-11-21T05:56:11.829047Z","iopub.status.idle":"2023-11-21T05:56:11.839523Z","shell.execute_reply":"2023-11-21T05:56:11.838805Z","shell.execute_reply.started":"2023-11-21T05:56:11.829337Z"},"trusted":true},"outputs":[],"source":["def depthwise_block1(in_c1, k1, iterations, dep_stride=2):\n","    in_c = in_c1\n","    k = k1\n","    init = nn.Sequential()\n","\n","    for i in range(iterations):\n","        init.add_module(\"some block\", nn.Sequential(\n","            nn.Conv2d(in_c, in_c, 3, stride=dep_stride, padding=1, groups=in_c),\n","            nn.BatchNorm2d(num_features=in_c),\n","            nn.ReLU(),\n","            nn.Conv2d(in_c, k*in_c, 1, stride=1, padding=0),\n","            nn.BatchNorm2d(num_features=k*in_c),\n","            nn.ReLU()\n","        ))\n","        in_c = k*in_c\n","    return init"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-21T05:56:11.840992Z","iopub.status.busy":"2023-11-21T05:56:11.840689Z","iopub.status.idle":"2023-11-21T05:56:11.857033Z","shell.execute_reply":"2023-11-21T05:56:11.856211Z","shell.execute_reply.started":"2023-11-21T05:56:11.840968Z"},"trusted":true},"outputs":[],"source":["class MobileNetV1(nn.Module):\n","    def __init__(self, in_channels=3, in_size=(224, 224), num_classes=train_dataset.features_amount, verbouse: bool = False):\n","        super(MobileNetV1, self).__init__()\n","        \n","        self._verbouse = verbouse\n","        \n","        self.in_size = in_size\n","        self.num_classes = num_classes\n","\n","        self.initial_layer = nn.Sequential(\n","            nn.Conv2d(in_channels, 32, 3, stride=2, padding=1),\n","            nn.BatchNorm2d(num_features=32),\n","            nn.ReLU(),\n","        )\n","\n","#         self.depthwise_layers = nn.Sequential()\n","\n","#         self.depthwise_layers.add_module(\"some block 1\",depthwise_block1(32, 2, 1, 1))\n","        self.depthwise_layers1 = depthwise_block1(32, 2, 1, 1)\n","\n","#         self.depthwise_layers.add_module(\"some block 2\",depthwise_block1(64, 2, 1, 2))\n","        self.depthwise_layers2 = depthwise_block1(64, 2, 1, 2)\n","\n","#         self.depthwise_layers.add_module(\"some block 3\",depthwise_block1(128, 1, 1, 1))\n","        self.depthwise_layers3 = depthwise_block1(128, 1, 1, 1)\n","\n","#         self.depthwise_layers.add_module(\"some block 4\", depthwise_block1(128, 2, 1, 2))\n","        self.depthwise_layers4 = depthwise_block1(128, 2, 1, 2)\n","\n","#         self.depthwise_layers.add_module(\"some block 5\",depthwise_block1(256, 1, 1, 1))\n","        self.depthwise_layers5 = depthwise_block1(256, 1, 1, 1)\n","\n","#         self.depthwise_layers.add_module(\"some block 6\",depthwise_block1(256, 2, 1, 2))\n","        self.depthwise_layers6 = depthwise_block1(256, 2, 1, 2)\n","\n","#         self.depthwise_layers.add_module(\"some block 7\",depthwise_block1(512, 1, 5, 1))\n","        self.depthwise_layers7 = depthwise_block1(512, 1, 5, 1)\n","\n","#         self.depthwise_layers.add_module(\"some block 8\",depthwise_block1(512, 2, 1, 2))\n","        self.depthwise_layers8 = depthwise_block1(512, 2, 1, 2)\n","\n","#         self.depthwise_layers.add_module(\"some block 9\",depthwise_block1(1024, 1, 1, 2))\n","        self.depthwise_layers9 = depthwise_block1(1024, 1, 1, 2)\n","    \n","        self.pooling_layers = nn.AvgPool2d(kernel_size=7, stride=1)\n","        self.fc_layer = nn.Linear(in_features=1024, out_features=num_classes)\n","        self.classifier_layer = nn.Softmax()\n","\n","    def forward(self, x):\n","        print(\"Input\", x.shape) if self._verbouse else None\n","        x = self.initial_layer(x)\n","        print(\"Initial\", x.shape) if self._verbouse else None\n","#         x = self.depthwise_layers(x)\n","        x =  self.depthwise_layers1(x)\n","        print(\"Depthwise 1\", x.shape) if self._verbouse else None\n","        x =  self.depthwise_layers2(x)\n","        print(\"Depthwise 2\", x.shape) if self._verbouse else None\n","        x =  self.depthwise_layers3(x)\n","        print(\"Depthwise 3\", x.shape) if self._verbouse else None\n","        x =  self.depthwise_layers4(x)\n","        print(\"Depthwise 4\", x.shape) if self._verbouse else None\n","        x =  self.depthwise_layers5(x)\n","        print(\"Depthwise 5\", x.shape) if self._verbouse else None\n","        x =  self.depthwise_layers6(x)\n","        print(\"Depthwise 6\", x.shape) if self._verbouse else None\n","        x =  self.depthwise_layers7(x)\n","        print(\"Depthwise 7\", x.shape) if self._verbouse else None\n","        x =  self.depthwise_layers8(x)\n","        print(\"Depthwise 8\", x.shape) if self._verbouse else None\n","#         x =  self.depthwise_layers9(x)\n","#         print(\"Depthwise 9\", x.shape)\n","        x = self.pooling_layers(x)\n","        print(\"Pooling\", x.shape) if self._verbouse else None\n","        x = self.classifier_layer(x)\n","        print(\"Classifier\", x.shape) if self._verbouse else None\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-21T05:56:11.858290Z","iopub.status.busy":"2023-11-21T05:56:11.858028Z","iopub.status.idle":"2023-11-21T05:56:11.871093Z","shell.execute_reply":"2023-11-21T05:56:11.870315Z","shell.execute_reply.started":"2023-11-21T05:56:11.858268Z"},"trusted":true},"outputs":[],"source":["def train_epoch(model: torch.nn.Module, dataloader: DataLoader, optimizer, loss_fn):\n","    total_loss = 0\n","\n","    model.train(True)\n","\n","    for i, t in enumerate(tqdm(dataloader)):\n","        inputs, labels = t\n","\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        outputs = outputs.view(outputs.shape[0], -1)\n","        \n","        loss = loss_fn(outputs, labels)\n","        loss.backward()\n","        total_loss += loss.item()\n","\n","        optimizer.step()\n","\n","    return total_loss / len(dataloader)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-21T05:56:11.872854Z","iopub.status.busy":"2023-11-21T05:56:11.872220Z","iopub.status.idle":"2023-11-21T05:56:11.883353Z","shell.execute_reply":"2023-11-21T05:56:11.882605Z","shell.execute_reply.started":"2023-11-21T05:56:11.872819Z"},"trusted":true},"outputs":[],"source":["def validate(model, dataloader, loss_fn):\n","    total_loss = 0\n","    pred_labels_ids = torch.Tensor().type(torch.int64)\n","    true_labels_ids = torch.Tensor().type(torch.int64)\n","\n","    model.eval()\n","\n","    with torch.no_grad():\n","        for i, t in enumerate(tqdm(dataloader)):\n","            inputs, labels = t\n","\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            outputs = model.forward(inputs)\n","            outputs = outputs.view(outputs.shape[0], -1)\n","            \n","            loss = loss_fn(outputs, labels)\n","\n","            total_loss += loss.item()\n","            true_labels_ids = torch.cat((true_labels_ids, labels.cpu().squeeze()))\n","            pred_labels_ids = torch.cat((pred_labels_ids, outputs.cpu().argmax(dim=-1, keepdim=False)))\n","\n","    # compute loss and metrics\n","    avg_vloss = total_loss / len(dataloader)\n","    accuracy = multiclass_accuracy(pred_labels_ids, true_labels_ids)\n","    f1 = multiclass_f1_score(pred_labels_ids, true_labels_ids, num_classes=test_dataset.features_amount, average='weighted')\n","    f1_macro = multiclass_f1_score(pred_labels_ids, true_labels_ids, num_classes=test_dataset.features_amount, average='macro')\n","\n","    return avg_vloss, accuracy.detach().numpy(), f1.detach().numpy(), f1_macro.detach().numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-21T05:56:11.884624Z","iopub.status.busy":"2023-11-21T05:56:11.884318Z","iopub.status.idle":"2023-11-21T05:56:11.899199Z","shell.execute_reply":"2023-11-21T05:56:11.898433Z","shell.execute_reply.started":"2023-11-21T05:56:11.884599Z"},"trusted":true},"outputs":[],"source":["def train_loop(model, train_loader, test_loader, optimizer, loss_fn, prefix, epochs=10):\n","    best_loss = 1e10\n","\n","    storage = {'Train loss': [], 'Valid loss': [], 'Accuracy': [], 'F1': [], 'F1 macro': []}\n","\n","    for epoch_number in range(epochs):\n","        print(f'\\nEpoch {epoch_number+1}:')\n","\n","        avg_train_loss = train_epoch(model, train_loader, optimizer, loss_fn)\n","        avg_val_loss, accuracy, f1, f1_macro = validate(model, test_loader, loss_fn)\n","\n","        print('\\nLoss train: {} valid {}'.format(avg_train_loss, avg_val_loss))\n","        print('Accuracy:', accuracy)\n","        print('F1:', f1)\n","        print('F1 macro:', f1_macro)\n","\n","        storage['Train loss'].append(avg_train_loss)\n","        storage['Valid loss'].append(avg_val_loss)\n","        storage['Accuracy'].append(accuracy)\n","        storage['F1'].append(f1)\n","        storage['F1 macro'].append(f1_macro)\n","\n","        # save best model\n","        if avg_val_loss < best_loss:\n","            best_loss = avg_val_loss\n","            model_path = f'{prefix}_{epoch_number+1}'\n","            torch.save(model.state_dict(), model_path)\n","\n","    return storage"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-21T05:56:11.902414Z","iopub.status.busy":"2023-11-21T05:56:11.902145Z","iopub.status.idle":"2023-11-21T05:56:11.914418Z","shell.execute_reply":"2023-11-21T05:56:11.913565Z","shell.execute_reply.started":"2023-11-21T05:56:11.902391Z"},"trusted":true},"outputs":[],"source":["def plot_history(history):\n","    plt.plot(history['Train loss'])\n","    plt.plot(history['Valid loss'])\n","    plt.title('model loss')\n","    plt.ylabel('loss')\n","    plt.xlabel('epoch')\n","    plt.legend(['train', 'val'], loc='upper left')\n","    plt.show()\n","\n","    plt.plot(history['Accuracy'])\n","    plt.plot(history['F1'])\n","    plt.plot(history['F1 macro'])\n","    plt.title('metrics')\n","    plt.ylabel('metrics')\n","    plt.xlabel('epoch')\n","    plt.legend(['Accuracy', 'F1', 'F1 macro'], loc='upper left')\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-21T05:56:11.915607Z","iopub.status.busy":"2023-11-21T05:56:11.915364Z"},"trusted":true},"outputs":[],"source":["model = MobileNetV1().to(device)\n","ce = torch.nn.CrossEntropyLoss().to(device)\n","adam = torch.optim.Adam(model.parameters(), lr=0.0005)\n","history = train_loop(model, train_loader, test_loader, adam, ce, 'test', 15)\n","plot_history(history)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":30084,"sourceId":38348,"sourceType":"datasetVersion"},{"datasetId":4031137,"sourceId":7011295,"sourceType":"datasetVersion"}],"dockerImageVersionId":30587,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
